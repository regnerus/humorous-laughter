{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textgrid as tg\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import librosa\n",
    "\n",
    "import h5py\n",
    "\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import delta\n",
    "from python_speech_features import logfbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, marks):\n",
    "        self.marks = marks\n",
    "        self.features = np.empty((0,187))\n",
    "        self.labels = np.empty(0)\n",
    "        self.df = pd.DataFrame(columns=[\"label\", \"features\"])\n",
    "    \n",
    "    def __loadWav(self, path):\n",
    "#         sig = AudioSegment.from_file(path, format=\"wav\")\n",
    "        X, sample_rate = sf.read(path, dtype='float32')\n",
    "\n",
    "        return X, sample_rate\n",
    "    \n",
    "    def __extractFeatures(self,segment, sample_rate):\n",
    "        samples = np.array(segment.get_array_of_samples())\n",
    "        frame_rate = segment.frame_rate\n",
    "\n",
    "        mfcc_feat = mfcc(samples, frame_rate, nfft=1103)\n",
    "        d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "        fbank_feat = logfbank(samples, frame_rate, nfft=1103)\n",
    "\n",
    "        return np.concatenate((np.array(mfcc_feat),np.array(d_mfcc_feat),np.array(fbank_feat)), axis=1)\n",
    "\n",
    "    def __extractFeaturesLibrosa(self,X, sample_rate):\n",
    "        X = X.T\n",
    "\n",
    "        # short term fourier transform\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "\n",
    "        # mfcc\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "\n",
    "        # chroma\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "        # melspectrogram\n",
    "        mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "\n",
    "        # spectral contrast\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "#         tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "        return mfccs,chroma,mel,contrast\n",
    "\n",
    "    \n",
    "    def extract(self, path):\n",
    "        for i, file in enumerate(os.listdir(path)):        \n",
    "            if file.endswith(\".TextGrid\"): \n",
    "                wav_path = os.path.join(path, os.path.splitext(file)[0] + '.wav')\n",
    "                if os.path.isfile(wav_path): \n",
    "                    sig, sample_rate = self.__loadWav(wav_path)\n",
    "                    \n",
    "                    textgrid_path = os.path.join(path, file)\n",
    "                    textgrid = tg.TextGrid.fromFile(textgrid_path)\n",
    "\n",
    "                    humorous_tier = textgrid[1]\n",
    "                    for interval in humorous_tier: #humorous tier\n",
    "                        if interval.mark in self.marks:\n",
    "                            start = int(interval.minTime * 1000)\n",
    "                            end = int(interval.maxTime * 1000)\n",
    "                            trimmed_sig = sig[start:end]\n",
    "                            label = self.marks.index(interval.mark)\n",
    "                            \n",
    "                            mfccs, chroma, mel, contrast = self.__extractFeaturesLibrosa(trimmed_sig, sample_rate)\n",
    "                            ext_features = np.hstack([mfccs,chroma,mel,contrast])\n",
    "                            self.features = np.vstack([self.features,ext_features])\n",
    "                            \n",
    "                            self.labels = np.append(self.labels, label)\n",
    "                            \n",
    "            \n",
    "        return np.array(self.features), np.array(self.labels, dtype = np.int)\n",
    "    \n",
    "#     def saveFeaturesHDF(self, path):\n",
    "#         filename = 'features{}.h5'.format(datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\"))\n",
    "#         self.df.to_hdf(os.path.join(path, filename),'df',mode='w',format='fixed',data_columns=True, compression='zlib')\n",
    "    \n",
    "#     def saveFeaturesCSV(self, path):\n",
    "#         filename = 'features{}.csv'.format(datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\"))\n",
    "#         self.df.to_csv(os.path.join(path, filename),mode='w')\n",
    "\n",
    "    def saveNumpy(self, path):\n",
    "        np.save(os.path.join(path, 'feat.npy'), self.features)\n",
    "        np.save(os.path.join(path, 'label.npy'), self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-498.00571094,  115.22830751,  -17.71747072, ...,   16.59821214,\n",
       "           20.49534195,   21.61198308],\n",
       "        [-519.22341526,  103.46712998,  -15.10817037, ...,   16.76542554,\n",
       "           18.82820224,   18.97010032],\n",
       "        [-417.47021286,  146.68699207,  -34.42571881, ...,   17.69312003,\n",
       "           15.66631595,   22.15552396],\n",
       "        ...,\n",
       "        [-401.12140477,  148.16541655,  -36.35623607, ...,   16.76183975,\n",
       "           16.63571731,   23.81582308],\n",
       "        [-495.78024875,  106.45667549,  -42.10897193, ...,   24.28949132,\n",
       "           32.09515495,   34.24728628],\n",
       "        [-450.51683619,  172.94091484,   11.55364805, ...,   21.974382  ,\n",
       "           16.99298938,   21.65583656]]),\n",
       " array([1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1]))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor = FeatureExtractor(['H', 'N'])\n",
    "\n",
    "extractor.extract('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor.saveNumpy('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
